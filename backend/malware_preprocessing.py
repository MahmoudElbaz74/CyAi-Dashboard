"""
Malware Analysis Module for CyAi-Dashboard
Reproduces the behavior of the Colab Xception model implementation
"""

import os
import logging
import numpy as np
from pathlib import Path
from typing import Optional, List, Tuple
from PIL import Image
import torch
import torch.nn as nn
from torchvision import transforms
import timm

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration dictionary (exactly as in Colab)
config = {
    "image_shape": (224, 224),
    "model": {
        "num_classes": 22,
        "in_channels": 1
    },
    "device": "cuda" if torch.cuda.is_available() else "cpu",
    "checkpoint_path": str(Path(__file__).resolve().parent / "models" / "mailware_analysis_model.ckpt"),
    "classes_names": [
        'AgentTesla', 'Amadey', 'AsyncRAT', 'AveMariaRAT', 'Benign', 'CobaltStrike',
        'Formbook', 'GCleaner', 'GandCrab', 'Gozi', 'GuLoader', 'Heodo', 'IcedID',
        'Loki', 'LummaStealer', 'Mirai', 'NanoCore', 'Prometei', 'RedLineStealer',
        'RemcosRAT', 'SilentBuilder', 'SmokeLoader'
    ]
}

logger.info(f"PyTorch device: {config['device']}")
logger.info(f"Checkpoint path: {config['checkpoint_path']}")


class LoadImage:
    """
    Custom transform class to convert .exe files to 1024x1024 grayscale images
    """
    
    def __init__(self):
        pass
    
    def __call__(self, malware_path: str) -> Image.Image:
        """
        Convert malware file to grayscale image
        
        Args:
            malware_path: Path to the malware file
            
        Returns:
            PIL Image in grayscale mode
        """
        return self.convertToImage(malware_path)
    
    def convertToImage(self, srcPath: str) -> Image.Image:
        """
        Convert binary file to 1024x1024 grayscale image
        
        Args:
            srcPath: Path to the source file
            
        Returns:
            PIL Image in grayscale mode
        """
        logger.info(f"Input file is: {os.path.basename(srcPath)}")
        
        try:
            with open(srcPath, "rb") as f:
                data = f.read()
            
            arr = np.frombuffer(data, dtype=np.uint8)
            length = arr.size
            
            # Calculate the number of bytes needed to reach 1024*1024
            needed = (1024 * 1024) - length
            
            if needed > 0:
                # Pad with zeros if file is smaller than 1024*1024
                arr = np.concatenate([arr, np.zeros(needed, dtype=np.uint8)])
            elif needed < 0:
                # Truncate if file is larger than 1024*1024
                arr = arr[:(1024 * 1024)]
            
            # Reshape to 1024x1024
            img = arr.reshape((1024, 1024))
            
            # Convert to grayscale image
            img = Image.fromarray(img, mode="L")
            
            return img
            
        except Exception as e:
            logger.error(f"Error converting file {srcPath} to image: {e}")
            raise


# Test transform pipeline
test_transform = transforms.Compose([
    LoadImage(),
    transforms.ToTensor(),
    transforms.Resize(config["image_shape"], antialias=True),
])


def load_model() -> nn.Module:
    """
    Load the Xception model with proper modifications for malware detection
    
    Returns:
        Loaded and configured PyTorch model
        
    Raises:
        FileNotFoundError: If checkpoint file is not found
        RuntimeError: If model loading fails
    """
    try:
        logger.info("Loading Xception model...")
        
        # Check if checkpoint exists
        if not os.path.exists(config["checkpoint_path"]):
            raise FileNotFoundError(f"Checkpoint not found at: {config['checkpoint_path']}")
        
        # Load pretrained Xception
        xception_engine = timm.create_model('xception', pretrained=True)
        logger.info("Pretrained Xception model loaded")
        
        # Modify the first convolutional layer to accept 1 input channel
        original_conv1 = xception_engine.conv1
        xception_engine.conv1 = nn.Conv2d(
            in_channels=config["model"]["in_channels"],
            out_channels=original_conv1.out_channels,
            kernel_size=original_conv1.kernel_size,
            stride=original_conv1.stride,
            padding=original_conv1.padding,
            bias=False
        )
        
        # Initialize with averaged RGB weights
        with torch.no_grad():
            xception_engine.conv1.weight = nn.Parameter(
                original_conv1.weight.mean(dim=1, keepdim=True)
            )
        
        # Modify the classifier layer to match the number of classes
        num_ftrs = xception_engine.fc.in_features
        xception_engine.fc = nn.Linear(num_ftrs, config["model"]["num_classes"])
        
        # Freeze all layers except the last few
        for name, param in xception_engine.named_parameters():
            # Unfreeze only specific layers
            if not any(layer_name in name for layer_name in ['fc', 'conv1', 'block14', 'bn4']):
                param.requires_grad = False
        
        logger.info("Model architecture modified for malware detection")
        
        # Load the checkpoint
        logger.info(f"Loading checkpoint from: {config['checkpoint_path']}")
        checkpoint_dict = torch.load(
            config["checkpoint_path"], 
            map_location=torch.device(config["device"])
        )
        
        # Extract state dict and remove 'engine.' prefix
        model_state_dict = checkpoint_dict['state_dict']
        new_state_dict = {}
        
        for k, v in model_state_dict.items():
            if k.startswith('engine.'):
                new_state_dict[k[7:]] = v  # Remove 'engine.' prefix
            else:
                new_state_dict[k] = v
        
        # Load the modified state dictionary into the model
        xception_engine.load_state_dict(new_state_dict, strict=False)
        
        # Move model to device and set to eval mode
        xception_engine = xception_engine.to(config["device"])
        xception_engine.eval()
        
        logger.info(f"Model loaded successfully on {config['device']}")
        return xception_engine
        
    except Exception as e:
        logger.error(f"Failed to load model: {e}")
        raise RuntimeError(f"Model loading failed: {e}")


def predict_malware(file_path: str, model: nn.Module) -> str:
    """
    Predict malware class for a given file
    
    Args:
        file_path: Path to the malware file
        model: Loaded PyTorch model
        
    Returns:
        Predicted class name
        
    Raises:
        FileNotFoundError: If file doesn't exist
        ValueError: If file is not a valid executable
    """
    try:
        # Validate file exists
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")
        
        # Check if file is executable (basic check)
        if not file_path.lower().endswith(('.exe', '.dll', '.sys', '.bin')):
            logger.warning(f"File {file_path} may not be a valid executable")
        
        logger.info(f"Predicting malware for: {os.path.basename(file_path)}")
        
        model.eval()
        
        with torch.no_grad():
            # Apply transform
            sample = test_transform(file_path)
            sample = sample.unsqueeze(0)  # Add batch dimension
            sample = sample.to(config["device"])
            
            # Run inference
            pred = model(sample)
            pred = torch.nn.Softmax(dim=1)(pred)
            
            # Get the index of the class with the highest probability
            predicted_class_index = torch.argmax(pred, dim=1).item()
            
            # Get the class name using the index
            predicted_class_name = config['classes_names'][predicted_class_index]
            
            # Get confidence score
            confidence = torch.max(pred).item()
            
            logger.info(f"Predicted class: {predicted_class_name} (confidence: {confidence:.4f})")
            
            return predicted_class_name
            
    except Exception as e:
        logger.error(f"Error predicting malware for {file_path}: {e}")
        raise


def batch_predict(directory: str, model: nn.Module) -> List[Tuple[str, str]]:
    """
    Automatically detect .exe files in a directory and predict malware for all
    
    Args:
        directory: Path to directory containing executable files
        model: Loaded PyTorch model
        
    Returns:
        List of tuples (filename, predicted_class)
    """
    results = []
    
    try:
        if not os.path.isdir(directory):
            raise ValueError(f"Directory not found: {directory}")
        
        logger.info(f"Scanning directory: {directory}")
        
        # Find all executable files
        exe_files = []
        for file in os.listdir(directory):
            if file.lower().endswith(('.exe', '.dll', '.sys', '.bin')):
                exe_files.append(file)
        
        if not exe_files:
            logger.warning(f"No executable files found in {directory}")
            return results
        
        logger.info(f"Found {len(exe_files)} executable files")
        
        # Predict each file
        for file in exe_files:
            try:
                file_path = os.path.join(directory, file)
                predicted_class = predict_malware(file_path, model)
                results.append((file, predicted_class))
                
            except Exception as e:
                logger.error(f"Failed to predict {file}: {e}")
                results.append((file, "ERROR"))
        
        return results
        
    except Exception as e:
        logger.error(f"Error in batch prediction: {e}")
        raise


def main():
    """
    Main function for testing the module
    """
    try:
        logger.info("Starting malware analysis module test...")
        
        # Load model
        model = load_model()
        
        # Test with a sample directory (create if it doesn't exist)
        samples_dir = Path(__file__).resolve().parent.parent / "samples"
        samples_dir.mkdir(exist_ok=True)
        
        logger.info(f"Testing with directory: {samples_dir}")
        
        # Check if directory has executable files
        if os.path.isdir(samples_dir):
            results = batch_predict(str(samples_dir), model)
            
            if results:
                print("\n" + "="*50)
                print("MALWARE ANALYSIS RESULTS")
                print("="*50)
                for filename, prediction in results:
                    print(f"{filename:<30} -> {prediction}")
                print("="*50)
            else:
                print(f"No executable files found in {samples_dir}")
                print("Place some .exe files in the samples/ directory to test")
        else:
            print(f"Directory {samples_dir} not found")
            
    except Exception as e:
        logger.error(f"Error in main: {e}")
        print(f"Error: {e}")


if __name__ == "__main__":
    main()
